{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_file = open(\"mnist_dataset/mnist_train_100.csv\", \"r\")\n",
    "data_list = data_file.readlines()\n",
    "data_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'5,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,3,18,18,18,126,136,175,26,166,255,247,127,0,0,0,0,0,0,0,0,0,0,0,0,30,36,94,154,170,253,253,253,253,253,225,172,253,242,195,64,0,0,0,0,0,0,0,0,0,0,0,49,238,253,253,253,253,253,253,253,253,251,93,82,82,56,39,0,0,0,0,0,0,0,0,0,0,0,0,18,219,253,253,253,253,253,198,182,247,241,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,80,156,107,253,253,205,11,0,43,154,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,14,1,154,253,90,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,139,253,190,2,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,11,190,253,70,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,35,241,225,160,108,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,81,240,253,253,119,25,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,45,186,253,253,150,27,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,16,93,252,253,187,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,249,253,249,64,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,46,130,183,253,253,207,2,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,39,148,229,253,253,253,250,182,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,24,114,221,253,253,253,253,201,78,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,23,66,213,253,253,253,253,198,81,2,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,18,171,219,253,253,253,253,195,80,9,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,55,172,226,253,253,253,253,244,133,11,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,136,253,253,253,212,135,132,16,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#,로 구분도니 픽셀값 리스트 변환\n",
    "all_values = data_list[0].split(',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#픽셀값 리스트를 28x28 배열로 변환\n",
    "image_array = numpy.asfarray(all_values[1:]).reshape((28,28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7c8e0f0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(image_array, cmap='Greys', interpolation = 'None')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.02164706 0.07988235 0.07988235 0.07988235\n",
      " 0.49917647 0.538      0.68941176 0.11094118 0.65447059 1.\n",
      " 0.96894118 0.50305882 0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.12647059 0.14976471 0.37494118 0.60788235\n",
      " 0.67       0.99223529 0.99223529 0.99223529 0.99223529 0.99223529\n",
      " 0.88352941 0.67776471 0.99223529 0.94952941 0.76705882 0.25847059\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.20023529\n",
      " 0.934      0.99223529 0.99223529 0.99223529 0.99223529 0.99223529\n",
      " 0.99223529 0.99223529 0.99223529 0.98447059 0.37105882 0.32835294\n",
      " 0.32835294 0.22741176 0.16141176 0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.07988235 0.86023529 0.99223529\n",
      " 0.99223529 0.99223529 0.99223529 0.99223529 0.77870588 0.71658824\n",
      " 0.96894118 0.94564706 0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.32058824 0.61564706 0.42541176 0.99223529\n",
      " 0.99223529 0.80588235 0.05270588 0.01       0.17694118 0.60788235\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.06435294 0.01388235 0.60788235 0.99223529 0.35941176\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.54964706 0.99223529 0.74764706 0.01776471 0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.05270588\n",
      " 0.74764706 0.99223529 0.28176471 0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.14588235 0.94564706\n",
      " 0.88352941 0.63117647 0.42929412 0.01388235 0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.32447059 0.94176471 0.99223529\n",
      " 0.99223529 0.472      0.10705882 0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.18470588 0.73211765 0.99223529 0.99223529\n",
      " 0.59235294 0.11482353 0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.07211765 0.37105882 0.98835294 0.99223529 0.736\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.97670588 0.99223529 0.97670588 0.25847059 0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.18858824 0.51470588 0.72047059 0.99223529\n",
      " 0.99223529 0.81364706 0.01776471 0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.16141176 0.58458824\n",
      " 0.89905882 0.99223529 0.99223529 0.99223529 0.98058824 0.71658824\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.10317647 0.45258824 0.868      0.99223529 0.99223529 0.99223529\n",
      " 0.99223529 0.79035294 0.31282353 0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.09929412 0.26623529 0.83694118 0.99223529\n",
      " 0.99223529 0.99223529 0.99223529 0.77870588 0.32447059 0.01776471\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.07988235 0.67388235\n",
      " 0.86023529 0.99223529 0.99223529 0.99223529 0.99223529 0.76705882\n",
      " 0.32058824 0.04494118 0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.22352941 0.67776471 0.88741176 0.99223529 0.99223529 0.99223529\n",
      " 0.99223529 0.95729412 0.52635294 0.05270588 0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.538      0.99223529\n",
      " 0.99223529 0.99223529 0.83305882 0.53411765 0.52247059 0.07211765\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01      ]\n"
     ]
    }
   ],
   "source": [
    "scaled_input = (numpy.asfarray(all_values[1:])/255.0*0.99)+ 0.01\n",
    "print(scaled_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.01 0.01 0.01 0.01 0.01 0.99 0.01 0.01 0.01 0.01]\n"
     ]
    }
   ],
   "source": [
    "#정답 레이블 - 정답이 4인 경우\n",
    "onodes = 10 #output node\n",
    "targets = numpy.zeros(onodes) + 0.01 #0값 피가히 위해 더하기\n",
    "targets[int(all_values[0])] = 0.99 #4에 0.99 배정\n",
    "print(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuralNetwork import neuralNetwork\n",
    "\n",
    "input_nodes = 784\n",
    "hidden_nodes = 100\n",
    "output_nodes = 10\n",
    "\n",
    "learning_rate = 0.5\n",
    "\n",
    "n=neuralNetwork(input_nodes, hidden_nodes, output_nodes,learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 신경망 학습시키기\n",
    "training_data_file = open(\"mnist_dataset/mnist_train.csv\", \"r\")\n",
    "training_data_list = training_data_file.readlines()\n",
    "training_data_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#테스트 데이터 모음 내의 모든 레코드 탐색\n",
    "for record in training_data_list:\n",
    "    # 레코드를 쉼표로 구분\n",
    "    all_values = record.split(',')\n",
    "    # 입력 값의 범위와 값 조정\n",
    "    inputs = (numpy.asfarray(all_values[1:])/255.0*0.99) + 0.01\n",
    "    # 결과 값 생성(정답은 0.99, 그 외는 모두 0.01)\n",
    "    targets = numpy.zeros(output_nodes) + 0.01\n",
    "    targets[int(all_values[0])] = 0.99\n",
    "    # 학습 데이터로 신경망 훈련시키기\n",
    "    n.train(inputs, targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 신경망 테스트하기\n",
    "test_data_file = open(\"mnist_dataset/mnist_test.csv\", \"r\")\n",
    "test_data_list = test_data_file.readlines()\n",
    "test_data_file.close()\n",
    "\n",
    "# 성적표(정답률)를 위한 테스트\n",
    "scorecard = []\n",
    "\n",
    "# 테스트 데이터 모음 내의 모든 레코드 탐색\n",
    "for record in test_data_list:\n",
    "    # 레코드를 쉼표로 구분\n",
    "    all_values = record.split(',')\n",
    "    # 정답은 첫번째 값\n",
    "    correct_label = int(all_values[0])\n",
    "    print(correct_label, \"correct label\")\n",
    "    # 입력 값의 범위와 값 조정\n",
    "    inputs = (numpy.asfarray(all_values[1:])/255.0*0.99) + 0.01\n",
    "    # 신경망에 질의\n",
    "    outputs = n.query(inputs)\n",
    "    \n",
    "    # 가장 높은 값의 인덱스는 레이블의 인덱스와 일치해야 함\n",
    "    label = numpy.argmax(outputs)\n",
    "    print(label, \"network's answer\")\n",
    "    # 정답 여부 판단\n",
    "    if(label == correct_label):\n",
    "        # 정답인 경우 성적표에 1을 추가\n",
    "        scorecard.append(1)\n",
    "    else:\n",
    "        # 정답이 아닌 경우 성적표에 0을 추가\n",
    "        scorecard.append(0)\n",
    "            \n",
    "#print(scorecard)\n",
    "scorecard_array = numpy.asarray(scorecard)\n",
    "print(\"performance = \", scorecard_array.sum() / scorecard_array.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuralNetwork import neuralNetwork\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "input_nodes = 784\n",
    "hidden_nodes = 100\n",
    "output_nodes = 10\n",
    "\n",
    "learning_rate = 0.5\n",
    "\n",
    "n=neuralNetwork(input_nodes, hidden_nodes, output_nodes,learning_rate)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_frame= pd.read_csv(\"mnist_dataset/mnist_train_10.csv\", header=None)\n",
    "test_values = data_frame.values\n",
    "test_labels = train_values[:,0:1]\n",
    "test_data = train_values[:,1:]/255.0*0.99 + 0.01\n",
    "scorecard = []\n",
    "\n",
    "for correct_label, inputs in zip(test_labels, test_data):\n",
    "    outputs = n.query(inputs)\n",
    "    \n",
    "    label = np.argmax(outputs)\n",
    "    # 정답 여부 판단\n",
    "    if(label == correct_label):\n",
    "        # 정답인 경우 성적표에 1을 추가\n",
    "        scorecard.append(1)\n",
    "    else:\n",
    "        # 정답이 아닌 경우 성적표에 0을 추가\n",
    "        scorecard.append(0)\n",
    "        \n",
    "#print(scorecard)\n",
    "scorecard_array = numpy.asarray(scorecard)\n",
    "print(\"performance = \", scorecard_array.sum() / scorecard_array.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuralNetwork import neuralNetwork\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "input_nodes = 784\n",
    "hidden_nodes = 100\n",
    "output_nodes = 10\n",
    "\n",
    "learning_rate = 0.5\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#신경망 인스턴스 생성\n",
    "n=neuralNetwork(input_nodes, hidden_nodes, output_nodes,learning_rate)\n",
    "\n",
    "#가중치만 저장시켜 따로 train\n",
    "n.train_from_file(\"mnist_dataset/mnist_train_100.csv\")\n",
    "n.save_weight(\"./mnist\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "performance =  0.2\n"
     ]
    }
   ],
   "source": [
    "#신경망 인스턴스 생성\n",
    "n=neuralNetwork(input_nodes, hidden_nodes, output_nodes, learning_rate, \"./mnist\")\n",
    "\n",
    "performance = n.query_from_file(\"mnist_dataset/mnist_test_10.csv\")\n",
    "print(\"performance = \", performance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>-0.33644710092114893</th>\n",
       "      <th>0.4265121358169459</th>\n",
       "      <th>-0.39685164123534283</th>\n",
       "      <th>-0.46389375117350906</th>\n",
       "      <th>-0.04957398962246584</th>\n",
       "      <th>0.1810502502577417</th>\n",
       "      <th>-0.22576611223643392</th>\n",
       "      <th>0.23334120069649353</th>\n",
       "      <th>0.1896498860082302</th>\n",
       "      <th>-0.38565796083398535</th>\n",
       "      <th>...</th>\n",
       "      <th>0.09059649709865747</th>\n",
       "      <th>0.6084554306421807</th>\n",
       "      <th>-0.4300698429173012</th>\n",
       "      <th>0.061925578126001225</th>\n",
       "      <th>-0.023092361578366007</th>\n",
       "      <th>0.11735830853580309</th>\n",
       "      <th>-0.2816757737282879</th>\n",
       "      <th>0.3143226881966379</th>\n",
       "      <th>-0.5905948963432741</th>\n",
       "      <th>0.2214560275503743</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.024349</td>\n",
       "      <td>-0.514921</td>\n",
       "      <td>-0.348270</td>\n",
       "      <td>0.009785</td>\n",
       "      <td>0.110092</td>\n",
       "      <td>-0.089011</td>\n",
       "      <td>0.075573</td>\n",
       "      <td>-0.164924</td>\n",
       "      <td>0.247856</td>\n",
       "      <td>0.127558</td>\n",
       "      <td>...</td>\n",
       "      <td>0.183979</td>\n",
       "      <td>0.121327</td>\n",
       "      <td>-0.361829</td>\n",
       "      <td>0.393390</td>\n",
       "      <td>0.340397</td>\n",
       "      <td>-0.335209</td>\n",
       "      <td>0.064003</td>\n",
       "      <td>-0.014926</td>\n",
       "      <td>-0.011063</td>\n",
       "      <td>0.266982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.052235</td>\n",
       "      <td>-0.191241</td>\n",
       "      <td>0.174570</td>\n",
       "      <td>-0.340698</td>\n",
       "      <td>-0.220879</td>\n",
       "      <td>0.463821</td>\n",
       "      <td>-0.059942</td>\n",
       "      <td>0.210930</td>\n",
       "      <td>-0.239885</td>\n",
       "      <td>-0.787075</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.128189</td>\n",
       "      <td>-0.183897</td>\n",
       "      <td>0.109101</td>\n",
       "      <td>-0.390402</td>\n",
       "      <td>0.047316</td>\n",
       "      <td>0.073392</td>\n",
       "      <td>0.221989</td>\n",
       "      <td>0.230640</td>\n",
       "      <td>-0.251071</td>\n",
       "      <td>-0.657793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.490482</td>\n",
       "      <td>0.039256</td>\n",
       "      <td>-0.101878</td>\n",
       "      <td>-0.605311</td>\n",
       "      <td>0.869295</td>\n",
       "      <td>0.245995</td>\n",
       "      <td>-0.148609</td>\n",
       "      <td>-0.051777</td>\n",
       "      <td>-0.292872</td>\n",
       "      <td>-0.488344</td>\n",
       "      <td>...</td>\n",
       "      <td>0.195087</td>\n",
       "      <td>0.168352</td>\n",
       "      <td>-0.228774</td>\n",
       "      <td>-0.369366</td>\n",
       "      <td>0.136995</td>\n",
       "      <td>0.486927</td>\n",
       "      <td>-0.069900</td>\n",
       "      <td>0.025495</td>\n",
       "      <td>-0.160401</td>\n",
       "      <td>-0.210305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.060150</td>\n",
       "      <td>0.012692</td>\n",
       "      <td>0.084845</td>\n",
       "      <td>-0.183077</td>\n",
       "      <td>-0.035408</td>\n",
       "      <td>-0.060933</td>\n",
       "      <td>0.371147</td>\n",
       "      <td>-0.009417</td>\n",
       "      <td>0.006658</td>\n",
       "      <td>0.528899</td>\n",
       "      <td>...</td>\n",
       "      <td>0.939511</td>\n",
       "      <td>0.152490</td>\n",
       "      <td>0.355365</td>\n",
       "      <td>0.221677</td>\n",
       "      <td>-0.388453</td>\n",
       "      <td>0.143238</td>\n",
       "      <td>-0.368682</td>\n",
       "      <td>0.129421</td>\n",
       "      <td>0.034269</td>\n",
       "      <td>0.143263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.026716</td>\n",
       "      <td>-0.261326</td>\n",
       "      <td>-0.285190</td>\n",
       "      <td>-0.002491</td>\n",
       "      <td>0.069826</td>\n",
       "      <td>0.249158</td>\n",
       "      <td>-0.420320</td>\n",
       "      <td>-0.186399</td>\n",
       "      <td>0.276298</td>\n",
       "      <td>-0.081505</td>\n",
       "      <td>...</td>\n",
       "      <td>0.160290</td>\n",
       "      <td>-0.293962</td>\n",
       "      <td>-0.066742</td>\n",
       "      <td>0.110797</td>\n",
       "      <td>0.064096</td>\n",
       "      <td>0.078250</td>\n",
       "      <td>0.093338</td>\n",
       "      <td>-0.463997</td>\n",
       "      <td>-0.031298</td>\n",
       "      <td>-1.133434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.228275</td>\n",
       "      <td>-0.033113</td>\n",
       "      <td>-0.180014</td>\n",
       "      <td>0.002579</td>\n",
       "      <td>-0.199551</td>\n",
       "      <td>-0.670388</td>\n",
       "      <td>0.046174</td>\n",
       "      <td>-0.107037</td>\n",
       "      <td>0.356603</td>\n",
       "      <td>-0.207742</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.374766</td>\n",
       "      <td>0.005968</td>\n",
       "      <td>0.618764</td>\n",
       "      <td>-0.487674</td>\n",
       "      <td>0.171769</td>\n",
       "      <td>0.584015</td>\n",
       "      <td>0.666411</td>\n",
       "      <td>-0.050719</td>\n",
       "      <td>-0.060241</td>\n",
       "      <td>-0.122596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-0.238927</td>\n",
       "      <td>-0.443348</td>\n",
       "      <td>-0.381746</td>\n",
       "      <td>-0.602968</td>\n",
       "      <td>-0.155797</td>\n",
       "      <td>0.198055</td>\n",
       "      <td>0.314655</td>\n",
       "      <td>-0.348473</td>\n",
       "      <td>0.145850</td>\n",
       "      <td>-0.066052</td>\n",
       "      <td>...</td>\n",
       "      <td>0.020332</td>\n",
       "      <td>0.035329</td>\n",
       "      <td>-0.284323</td>\n",
       "      <td>0.038816</td>\n",
       "      <td>-0.212276</td>\n",
       "      <td>0.140903</td>\n",
       "      <td>-0.141605</td>\n",
       "      <td>0.067665</td>\n",
       "      <td>-0.442802</td>\n",
       "      <td>-1.026210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.218450</td>\n",
       "      <td>0.464753</td>\n",
       "      <td>-0.459913</td>\n",
       "      <td>-0.101076</td>\n",
       "      <td>-0.262133</td>\n",
       "      <td>-0.109853</td>\n",
       "      <td>-0.146778</td>\n",
       "      <td>0.418017</td>\n",
       "      <td>-0.194383</td>\n",
       "      <td>-0.408745</td>\n",
       "      <td>...</td>\n",
       "      <td>0.553949</td>\n",
       "      <td>0.202220</td>\n",
       "      <td>-0.241140</td>\n",
       "      <td>-0.248091</td>\n",
       "      <td>-0.230300</td>\n",
       "      <td>-0.065659</td>\n",
       "      <td>0.090600</td>\n",
       "      <td>-0.049685</td>\n",
       "      <td>-0.146930</td>\n",
       "      <td>-0.263091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-0.504657</td>\n",
       "      <td>0.182902</td>\n",
       "      <td>-0.115229</td>\n",
       "      <td>0.051876</td>\n",
       "      <td>-0.136252</td>\n",
       "      <td>0.085285</td>\n",
       "      <td>-0.056658</td>\n",
       "      <td>-0.210442</td>\n",
       "      <td>0.354613</td>\n",
       "      <td>-0.004027</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.010434</td>\n",
       "      <td>-0.298628</td>\n",
       "      <td>-0.331486</td>\n",
       "      <td>-0.262867</td>\n",
       "      <td>-0.167438</td>\n",
       "      <td>-0.739875</td>\n",
       "      <td>0.413617</td>\n",
       "      <td>-0.294857</td>\n",
       "      <td>-0.539614</td>\n",
       "      <td>-0.404219</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9 rows × 100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   -0.33644710092114893  0.4265121358169459  -0.39685164123534283  \\\n",
       "0              0.024349           -0.514921             -0.348270   \n",
       "1             -0.052235           -0.191241              0.174570   \n",
       "2              0.490482            0.039256             -0.101878   \n",
       "3             -0.060150            0.012692              0.084845   \n",
       "4             -0.026716           -0.261326             -0.285190   \n",
       "5              0.228275           -0.033113             -0.180014   \n",
       "6             -0.238927           -0.443348             -0.381746   \n",
       "7              0.218450            0.464753             -0.459913   \n",
       "8             -0.504657            0.182902             -0.115229   \n",
       "\n",
       "   -0.46389375117350906  -0.04957398962246584  0.1810502502577417  \\\n",
       "0              0.009785              0.110092           -0.089011   \n",
       "1             -0.340698             -0.220879            0.463821   \n",
       "2             -0.605311              0.869295            0.245995   \n",
       "3             -0.183077             -0.035408           -0.060933   \n",
       "4             -0.002491              0.069826            0.249158   \n",
       "5              0.002579             -0.199551           -0.670388   \n",
       "6             -0.602968             -0.155797            0.198055   \n",
       "7             -0.101076             -0.262133           -0.109853   \n",
       "8              0.051876             -0.136252            0.085285   \n",
       "\n",
       "   -0.22576611223643392  0.23334120069649353  0.1896498860082302  \\\n",
       "0              0.075573            -0.164924            0.247856   \n",
       "1             -0.059942             0.210930           -0.239885   \n",
       "2             -0.148609            -0.051777           -0.292872   \n",
       "3              0.371147            -0.009417            0.006658   \n",
       "4             -0.420320            -0.186399            0.276298   \n",
       "5              0.046174            -0.107037            0.356603   \n",
       "6              0.314655            -0.348473            0.145850   \n",
       "7             -0.146778             0.418017           -0.194383   \n",
       "8             -0.056658            -0.210442            0.354613   \n",
       "\n",
       "   -0.38565796083398535         ...          0.09059649709865747  \\\n",
       "0              0.127558         ...                     0.183979   \n",
       "1             -0.787075         ...                    -0.128189   \n",
       "2             -0.488344         ...                     0.195087   \n",
       "3              0.528899         ...                     0.939511   \n",
       "4             -0.081505         ...                     0.160290   \n",
       "5             -0.207742         ...                    -0.374766   \n",
       "6             -0.066052         ...                     0.020332   \n",
       "7             -0.408745         ...                     0.553949   \n",
       "8             -0.004027         ...                    -0.010434   \n",
       "\n",
       "   0.6084554306421807  -0.4300698429173012  0.061925578126001225  \\\n",
       "0            0.121327            -0.361829              0.393390   \n",
       "1           -0.183897             0.109101             -0.390402   \n",
       "2            0.168352            -0.228774             -0.369366   \n",
       "3            0.152490             0.355365              0.221677   \n",
       "4           -0.293962            -0.066742              0.110797   \n",
       "5            0.005968             0.618764             -0.487674   \n",
       "6            0.035329            -0.284323              0.038816   \n",
       "7            0.202220            -0.241140             -0.248091   \n",
       "8           -0.298628            -0.331486             -0.262867   \n",
       "\n",
       "   -0.023092361578366007  0.11735830853580309  -0.2816757737282879  \\\n",
       "0               0.340397            -0.335209             0.064003   \n",
       "1               0.047316             0.073392             0.221989   \n",
       "2               0.136995             0.486927            -0.069900   \n",
       "3              -0.388453             0.143238            -0.368682   \n",
       "4               0.064096             0.078250             0.093338   \n",
       "5               0.171769             0.584015             0.666411   \n",
       "6              -0.212276             0.140903            -0.141605   \n",
       "7              -0.230300            -0.065659             0.090600   \n",
       "8              -0.167438            -0.739875             0.413617   \n",
       "\n",
       "   0.3143226881966379  -0.5905948963432741  0.2214560275503743  \n",
       "0           -0.014926            -0.011063            0.266982  \n",
       "1            0.230640            -0.251071           -0.657793  \n",
       "2            0.025495            -0.160401           -0.210305  \n",
       "3            0.129421             0.034269            0.143263  \n",
       "4           -0.463997            -0.031298           -1.133434  \n",
       "5           -0.050719            -0.060241           -0.122596  \n",
       "6            0.067665            -0.442802           -1.026210  \n",
       "7           -0.049685            -0.146930           -0.263091  \n",
       "8           -0.294857            -0.539614           -0.404219  \n",
       "\n",
       "[9 rows x 100 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv('./mnist_who.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
